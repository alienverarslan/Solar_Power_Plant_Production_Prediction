{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T09:18:27.823773Z",
     "start_time": "2022-03-01T09:18:27.817773Z"
    }
   },
   "outputs": [],
   "source": [
    "# univariate multi-step encoder-decoder cnn-lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T12:47:05.651067Z",
     "start_time": "2022-03-01T12:47:05.405893Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lagged Data\n",
    "X = read_csv('X_imp_cl_model_lag2.csv', index_col='DateTime', parse_dates=['DateTime'] )\n",
    "X = X.rename(columns={'var1(t-24)': 'generation_t_24'})\n",
    "\n",
    "y_lagged = read_csv('y_lag.csv', index_col='DateTime', parse_dates=['DateTime'])\n",
    "y = pd.read_csv('generation_data.csv', parse_dates=['DateTime'], index_col=[\"DateTime\"])\n",
    "X_test = read_csv('X_imp_cl_test_lag.csv', index_col='DateTime', parse_dates=['DateTime'])\n",
    "X_test = X_test.rename(columns={'var1(t-24)': 'generation_t_24'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:21:05.780567Z",
     "start_time": "2022-03-01T13:21:05.757565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:00:00</th>\n",
       "      <td>0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 21:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 22:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 23:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24840 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Generation\n",
       "DateTime                       \n",
       "2019-01-01 00:00:00    0.000000\n",
       "2019-01-01 01:00:00    0.000000\n",
       "2019-01-01 02:00:00    0.000008\n",
       "2019-01-01 03:00:00    0.000000\n",
       "2019-01-01 04:00:00    0.000008\n",
       "...                         ...\n",
       "2021-10-31 19:00:00    0.010345\n",
       "2021-10-31 20:00:00    0.000000\n",
       "2021-10-31 21:00:00    0.000000\n",
       "2021-10-31 22:00:00    0.000000\n",
       "2021-10-31 23:00:00    0.000000\n",
       "\n",
       "[24840 rows x 1 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[:24840,:]#[:'2021-10-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T12:47:32.841114Z",
     "start_time": "2022-03-01T12:47:32.803968Z"
    }
   },
   "outputs": [],
   "source": [
    "merged = X.merge(y[\"Generation\"], left_index=True, right_index=True, how='inner')\n",
    "merged = merged.drop('generation_t_24', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:21:15.739908Z",
     "start_time": "2022-03-01T13:21:15.730909Z"
    }
   },
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "# split into standard weeks\n",
    "    train, test = data[0:24840], data[24840:]\n",
    "# restructure into windows of weekly data\n",
    "    train = array(split(train, len(train)/24))\n",
    "    test = array(split(test, len(test)/24))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T09:54:44.338141Z",
     "start_time": "2022-03-01T09:54:44.322143Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T09:54:45.272695Z",
     "start_time": "2022-03-01T09:54:45.261695Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T09:54:46.465566Z",
     "start_time": "2022-03-01T09:54:46.450528Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=24):\n",
    "# flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end < len(data):\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:17:53.519983Z",
     "start_time": "2022-03-01T13:17:53.507023Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 1, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(25, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[RootMeanSquaredError()])\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:08:16.345769Z",
     "start_time": "2022-03-01T13:08:16.335777Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, 0]\n",
    "    # reshape into [1, n_input, 1]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T09:54:49.231657Z",
     "start_time": "2022-03-01T09:54:49.215657Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    # fit model\n",
    "    model = build_model(train, n_input)\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:24:45.365329Z",
     "start_time": "2022-03-01T13:24:45.352360Z"
    }
   },
   "outputs": [],
   "source": [
    "merged = merged[['Generation', 'AirTemperature_t','wwcode_cluster_t',\n",
    "                 'ComfortTemperature_t','RelativeHumidity_t',\n",
    "                 'WindSpeed_t', 'WindDirection_t', 'is_holiday_t',\n",
    "                 'WWCode_t',  'EffectiveCloudCover_t', 'Hour_t',\n",
    "                 'DayGroup_t', 'Month_t',  'Day_t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:26:31.101617Z",
     "start_time": "2022-03-01T13:24:46.771814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "775/775 [==============================] - 11s 13ms/step - loss: 13453.2207 - root_mean_squared_error: 115.9881\n",
      "Epoch 2/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 9961.5791 - root_mean_squared_error: 99.8077\n",
      "Epoch 3/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 6001.4487 - root_mean_squared_error: 77.4690\n",
      "Epoch 4/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 6568.5962 - root_mean_squared_error: 81.0469\n",
      "Epoch 5/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 4604.5537 - root_mean_squared_error: 67.8569\n",
      "Epoch 6/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 5657.2642 - root_mean_squared_error: 75.2148\n",
      "Epoch 7/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 7248.5918 - root_mean_squared_error: 85.1387\n",
      "Epoch 8/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 5692.3384 - root_mean_squared_error: 75.4476\n",
      "Epoch 9/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 3649.3181 - root_mean_squared_error: 60.4096\n",
      "Epoch 10/10\n",
      "775/775 [==============================] - 10s 13ms/step - loss: 2991.2900 - root_mean_squared_error: 54.6927\n"
     ]
    }
   ],
   "source": [
    "n_input = 24\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "# split into standard weeks\n",
    "    train, test = data[0:24840], data[24840:]#23352\n",
    "# restructure into windows of weekly data\n",
    "    train = array(split(train, len(train)/24))\n",
    "    test = array(split(test, len(test)/24))\n",
    "    return train, test\n",
    "\n",
    "train, test = split_dataset(merged)\n",
    "\n",
    "model = build_model(train, n_input)\n",
    "\n",
    "\n",
    "history_test = [x for x in test]\n",
    "\n",
    "\n",
    "# walk-forward validation over each week\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    # predict the week\n",
    "    yhat_sequence = forecast(model, history_test, n_input)\n",
    "    predictions.append(yhat_sequence)\n",
    "    # get real observation and add to history for predicting the next week\n",
    "    history_test.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "predictions = array(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:28:52.983491Z",
     "start_time": "2022-03-01T13:28:52.971528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377.56927\n",
      "-60.58003\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions.flat).max())\n",
    "print(np.array(predictions.flat).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:29:08.738880Z",
     "start_time": "2022-03-01T13:29:08.725905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.838869341290014"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_capacity = 523.005001\n",
    "\n",
    "y_test = np.array([total_capacity*0.98 if i > total_capacity else 0 if i < 0 else i for i in np.array(predictions.flat)])\n",
    "\n",
    "mean_squared_error(test.reshape(-1, 14)[:,0], y_test, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
